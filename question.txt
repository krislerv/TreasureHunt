The agent's next action is decided by a set of rules, primarily which stage it is in. The stages are called SAFE, WATER, LUMBERJACK, BOMBERMAN, and PLANNED. Basically, the agent will exhaust it's options in one stage, then go to the PLANNED stage, then go to the next stage. In the SAFE stage the agent safely (using no dynamite and cutting no trees) explores the area it's in and collects items. In the WATER stage it cuts down a tree and tries to explore the ocean. In the LUMBERJACK stage it explores the map using as many trees as it wants. In the BOMBERMAN stage it tries to accumulate dynamite by blowing up walls (i.e. blow up one wall to get two more dynamite). In the PLANNED stage it tries to plan a path from it's current position to the gold, then to the start position. In addition to all this, there are some special rules that are used to increase performance and solve some edge cases.

The algorithms used are breath-first search, Dijkstra's algorithmn, and A*.
BFS was used to find unexplored tiles to explore. It's implementation is pretty standard, but a bit simplified since we are not looking for a path, just a single tile.
Dijkstra's algorithm was used to find least dynamite paths (useful in BOMBERMAN and PLANNED) and to find the closest water tile (useful in WATER).
A* was the main pathfinding algorithm used. It is mostly a standard implementation, but with a few modifications. It has a cutoff point (currently when the closed set has 25000 items) to avoid it running on for a very long time on large maps. Its neighbor generation method generates neighbors based on what stage the agent is currently in. For example, if the agent is in the WATER stage, it will only generate neighbor states where the agent is standing on water. The heuristic used is different depending on the circumstances. If the agent is not trying to find a path to the gold and home, then the heuristic is the manhattan distance. If it is trying to find such a path, then the heuristic is the sum of the manhattan distance to the gold (if not collected) to the start state plus the sum of a (non-optimal) path from the agent through every known dynamite on the map. The heuristic is not admissible. This was done because we don't care about an optimal path, we just want to find a viable path as fast as possible.
To keep track of everything, there is the WorldModel class. This class keeps a map on everything the agent has seen. The State class is used as nodes in the search algorithms. It keeps track of the agent's position, orientation, inventory, and which tiles it has blown up/unlocked/chopped down. All this allows the search algorithms to perform searches where the agent does many different types of actions to find a solution.